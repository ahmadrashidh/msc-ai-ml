{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMYsd856bkTMeTze2mZG1nA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Etivity 6\n","\n","Student Name: Ahmad Rashidh Ameer Hamsha\n","\n","Student ID: 23264306"],"metadata":{"id":"ObZ3ZYWYb0oW"}},{"cell_type":"markdown","source":["## Task 2\n","\n","Given the two confusion tables below, compute\n","Microaveraged precision, recall, and F1\n","Macroaveraged precision, recall, and F1\n","Explain the reason for the difference between the obtained Microaveraged and Macroaveraged F1 measures.\n"],"metadata":{"id":"24xUlCm_dI85"}},{"cell_type":"markdown","source":["### Microavergaed Precision\n","\n","\\begin{align}\n","P_{micro} = \\frac{TP_1 + TP_2}{TP_1 + TP_2 + FP_1 + FP_2}\n","\\end{align}\n","\n","\\begin{align}\n","Precision Microaveraged = \\frac{800 + 70}{800 + 70 + 200 + 30}\n","\\end{align}\n","\n","\\begin{align}\n","Precision Microaveraged = \\frac{870}{1100} = 0.79\n","\\end{align}\n","\n","### Microavergaed Recall\n","\n","\\begin{align}\n","Recall Microaveraged = \\frac{TP_1 + TP_2}{TP_1 + TP_2 + FN_1 + FN_2}\n","\\end{align}\n","\n","\\begin{align}\n","Recall Microaveraged = \\frac{800 + 70}{800 + 70 + 200 + 30}\n","\\end{align}\n","\n","\\begin{align}\n","Recall Microaveraged = \\frac{870}{1100} = 0.79\n","\\end{align}\n","\n","### Microavergaed F1\n","\n","\\begin{align}\n","F1 = \\frac{(\\beta^2 + 1)(PR)}{\\beta^2P + R}\n","\\end{align}\n","\n","\\begin{align}\n","With β = 1,\n","F1 = \\frac{(2)(0.79 * 0.79)}{0.79 + 0.79}\n","\\end{align}\n","\n","\\begin{align}\n","F1 = \\frac{1.2482}{1.58} = 0.79\n","\\end{align}\n","\n","\n","### Macroaveraged Precision\n","\n","\\begin{align}\n","Precision_1 = \\frac{TP_1}{TP_1 + FP_1}\n","\\end{align}\n","\n","\\begin{align}\n","Precision_1 = \\frac{800}{800 + 200}\n","\\end{align}\n","\n","\\begin{align}\n","Precision_1 = \\frac{800}{1000} = 0.8\n","\\end{align}\n","\n","\\begin{align}\n","Precision_2 = \\frac{TP_2}{TP_2 + FP_2}\n","\\end{align}\n","\n","\\begin{align}\n","Precision_2 = \\frac{70}{70 + 30}\n","\\end{align}\n","\n","\\begin{align}\n","Precision_2 = \\frac{70}{100} = 0.7\n","\\end{align}\n","\n","\n","\\begin{align}\n","Precision Microaveraged = \\frac{Precision_1 + Precision_2}{n}\n","\\end{align}\n","\n","\\begin{align}\n","Precision Microaveraged = \\frac{0.8 + 0.7}{2} = 0.75\n","\\end{align}\n","\n","### Macroaveraged Recall\n","\n","\n","\\begin{align}\n","Recall_1 = \\frac{TP_1}{TP_1 + FN_1}\n","\\end{align}\n","\n","\\begin{align}\n","Recall_1 = \\frac{800}{800 + 200}\n","\\end{align}\n","\n","\\begin{align}\n","Recall_1 = \\frac{800}{1000} = 0.8\n","\\end{align}\n","\n","\\begin{align}\n","Recall_2 = \\frac{TP_2}{TP_2 + FN_2}\n","\\end{align}\n","\n","\\begin{align}\n","Recall_2 = \\frac{70}{70 + 30}\n","\\end{align}\n","\n","\\begin{align}\n","Recall_2 = \\frac{70}{100} = 0.7\n","\\end{align}\n","\n","### Macroaveraged F1\n","\n","\\begin{align}\n","F1 = \\frac{(\\beta^2 + 1)(PR)}{\\beta^2P + R}\n","\\end{align}\n","\n","\\begin{align}\n","With β = 1,\n","F1 = \\frac{(2)(0.8 * 0.7)}{0.8 + 0.7}\n","\\end{align}\n","\n","\\begin{align}\n","F1 = \\frac{1.12}{1.5} = 0.74\n","\\end{align}\n","\n"],"metadata":{"id":"RUuEtOjtdLMc"}},{"cell_type":"markdown","source":["### Difference\n","\n","The difference in microaveraged and macroaveraged F1 measures is because of the class distributions in the dataset.\n","\n","The microaveraged F1 will measure the total true postivies, false postivies and false negatives without taking class contribution in account, thus higher score will be given if the classifier is good particulary in the majority class. Whereas macroaveraged F1 would take the metric for each class independently and the avrage score is computed, therfore  poor performance will be on minority class, F1 score would be lowered."],"metadata":{"id":"53cwPmXKx9XI"}},{"cell_type":"markdown","source":["## Task 2\n","\n","Modify the Multinomial Naïve Bayes classifier function that you developed in Etivity5, Task3 to train and test a sentiment classifier using the data shown in the table below."],"metadata":{"id":"4ObU9s7TmNe0"}},{"cell_type":"code","source":["def naiveBayesSentimentClassifier(trainingSet, testSet):\n","\n","  def getBagOfWords(doc):\n","    bagOfWords = {}\n","    for word in doc:\n","        if word in bagOfWords:\n","            bagOfWords[word] += 1\n","        else:\n","            bagOfWords[word] = 1\n","    return bagOfWords\n","\n","  def getMegaDoc(trainingSet, c):\n","    result = []\n","    for doc in trainingSet:\n","      if doc[1] == c:\n","        result.append(doc[0].lower())\n","\n","    return \" \".join(result)\n","\n","  megaDocNeg = getMegaDoc(trainingSet, '-')\n","  megaDocPos = getMegaDoc(trainingSet,'+')\n","\n","  print(f'megaDocNeg = {megaDocNeg}')\n","  print(f'megaDocPos = {megaDocPos}')\n","\n","  docCountNeg = len([doc[1] for doc in trainingSet if doc[1] == '-'])\n","  docCountPos = len([doc[1] for doc in trainingSet if doc[1] == '+'])\n","\n","  probGB = docCountNeg/len(trainingSet)\n","  probIE = docCountPos/len(trainingSet)\n","  print(f'probGB = {probGB}\\tprobIE = {probIE}')\n","\n","  Neg_BoW = getBagOfWords(megaDocNeg.split())\n","  Pos_BoW = getBagOfWords(megaDocPos.split())\n","  print(f'Negative_BoW = {Neg_BoW}')\n","  print(f'Positive_BoW = {Pos_BoW}')\n","\n","\n","  V = getBagOfWords(megaDocNeg.split() + megaDocPos.split())\n","  print(f'V = {V}')\n","  print(f'|V| = {len(V)}\\n')\n","\n","  for test in testSet:\n","        print('-------------------------------------------------------------')\n","        print(f'Test document = {test}\\n')\n","        documentProbGB, documentProbIE = probGB, probIE\n","        for w in test[0].split():\n","\n","            w = w.lower()\n","\n","            if w not in V:\n","                continue\n","\n","            if w in Neg_BoW:\n","                conditionalProbGB = (Neg_BoW[w] + 1)/(len(megaDocNeg.split()) + len(V))\n","            else:\n","                conditionalProbGB = 1/(len(megaDocNeg.split()) + len(V))\n","\n","            if w in Pos_BoW:\n","                conditionalProbIE = (Pos_BoW[w] + 1)/(len(megaDocPos.split()) + len(V))\n","            else:\n","                conditionalProbIE = 1/(len(megaDocPos.split()) + len(V))\n","\n","            print(f'word = \"{w}\"\\nwordConditionalProbNeg = {conditionalProbGB}\\nwordConditionalProbPos = {conditionalProbIE}')\n","\n","            documentProbGB *= conditionalProbGB\n","            documentProbIE *= conditionalProbIE\n","\n","        print(f'\\nDocProbNeg = {documentProbGB}   \\nDocProbPos = {documentProbIE}')\n","        if documentProbGB > documentProbIE:\n","            inferredClass = '-'\n","        else:\n","            inferredClass = '+'\n","\n","        print(f'Inferred class = {inferredClass}')"],"metadata":{"id":"7QYplzFpeJBk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","trainingSet = [('just plain boring','-'),('entirely predictable and lacks energy','-'),('no surprises and very few laughs','-'),('very powerful','+'),('the most fun film of the summer','+')]\n","testSet = [('predictable with no fun','?')]\n","naiveBayesSentimentClassifier(trainingSet, testSet)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OI_PlDeOwMJg","executionInfo":{"status":"ok","timestamp":1700836904648,"user_tz":0,"elapsed":5,"user":{"displayName":"Ahmad Rashidh","userId":"17250827789938225012"}},"outputId":"d26e987c-3ca5-49fd-cf37-95e10f28c29a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["megaDocNeg = just plain boring entirely predictable and lacks energy no surprises and very few laughs\n","megaDocPos = very powerful the most fun film of the summer\n","probGB = 0.6\tprobIE = 0.4\n","Negative_BoW = {'just': 1, 'plain': 1, 'boring': 1, 'entirely': 1, 'predictable': 1, 'and': 2, 'lacks': 1, 'energy': 1, 'no': 1, 'surprises': 1, 'very': 1, 'few': 1, 'laughs': 1}\n","Positive_BoW = {'very': 1, 'powerful': 1, 'the': 2, 'most': 1, 'fun': 1, 'film': 1, 'of': 1, 'summer': 1}\n","V = {'just': 1, 'plain': 1, 'boring': 1, 'entirely': 1, 'predictable': 1, 'and': 2, 'lacks': 1, 'energy': 1, 'no': 1, 'surprises': 1, 'very': 2, 'few': 1, 'laughs': 1, 'powerful': 1, 'the': 2, 'most': 1, 'fun': 1, 'film': 1, 'of': 1, 'summer': 1}\n","|V| = 20\n","\n","-------------------------------------------------------------\n","Test document = ('predictable with no fun', '?')\n","\n","word = \"predictable\"\n","wordConditionalProbNeg = 0.058823529411764705\n","wordConditionalProbPos = 0.034482758620689655\n","word = \"no\"\n","wordConditionalProbNeg = 0.058823529411764705\n","wordConditionalProbPos = 0.034482758620689655\n","word = \"fun\"\n","wordConditionalProbNeg = 0.029411764705882353\n","wordConditionalProbPos = 0.06896551724137931\n","\n","DocProbNeg = 6.106248727864848e-05   \n","DocProbPos = 3.2801672885317154e-05\n","Inferred class = -\n"]}]},{"cell_type":"markdown","source":["### Task 3\n","\n","Write a Sentiment Analysis function that takes a string as input and identifies its sentiment using the TextBlob library."],"metadata":{"id":"y-R9JShHmiXS"}},{"cell_type":"code","source":["from textblob import TextBlob"],"metadata":{"id":"ixotgPNAmlNQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sentimentAnalyzer(sentence):\n","  print(f\"string= {sentence}\")\n","  testimonial = TextBlob(sentence)\n","  print(testimonial.sentiment)\n","  if testimonial.sentiment.polarity < -0.1:\n","    print('negative sentiment')\n","  elif testimonial.sentiment.polarity > 0.1:\n","    print('negative sentiment')\n","  else:\n","    print('neutral sentiment')\n","\n","  print(f\"Subjectivity:{testimonial.sentiment.subjectivity}\")\n","  print(\"-------------------------------------------------\")\n"],"metadata":{"id":"lQ-q-b8amoQY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentimentAnalyzer(\"NLP is cool\")\n","sentimentAnalyzer(\"NLP is cool and useful\")\n","sentimentAnalyzer(\"NLP is hard\")\n","sentimentAnalyzer(\"NLP is hard and useless\")\n","sentimentAnalyzer(\"NLP stands for Natural Language Processing\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zn06gG8wodAj","executionInfo":{"status":"ok","timestamp":1700834642239,"user_tz":0,"elapsed":5,"user":{"displayName":"Ahmad Rashidh","userId":"17250827789938225012"}},"outputId":"6b37a5c0-1385-43c2-ce89-252d98649f05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["string= NLP is cool\n","Sentiment(polarity=0.35, subjectivity=0.65)\n","negative sentiment\n","Subjectivity:0.65\n","-------------------------------------------------\n","string= NLP is cool and useful\n","Sentiment(polarity=0.32499999999999996, subjectivity=0.325)\n","negative sentiment\n","Subjectivity:0.325\n","-------------------------------------------------\n","string= NLP is hard\n","Sentiment(polarity=-0.2916666666666667, subjectivity=0.5416666666666666)\n","negative sentiment\n","Subjectivity:0.5416666666666666\n","-------------------------------------------------\n","string= NLP is hard and useless\n","Sentiment(polarity=-0.39583333333333337, subjectivity=0.37083333333333335)\n","negative sentiment\n","Subjectivity:0.37083333333333335\n","-------------------------------------------------\n","string= NLP stands for Natural Language Processing\n","Sentiment(polarity=0.1, subjectivity=0.4)\n","neutral sentiment\n","Subjectivity:0.4\n","-------------------------------------------------\n"]}]}]}