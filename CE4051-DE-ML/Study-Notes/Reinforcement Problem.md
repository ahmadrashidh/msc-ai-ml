- No labelled data, but model learns by 

Model learns based credit assignment. For example, positive reward provided if prediction seems right or negative reward if prediction seems wrong is used to create gradient descent of probabilities.

**Glossary**

Credit Assignment Problem - it is uncertain that model can achieve positive credit only on end goal by doing random actions.

Reward Shaping - Designing reward function that will guide model to achieve desired action/results. It is custom extensive process, not an optimal solution.

The Alignment Problem - Agent will find surprising result out of reward function without intended behaviour.

